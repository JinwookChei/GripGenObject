{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 139)\n",
      "(2000, 139)\n",
      "(2000, 139)\n",
      "(2000, 139)\n",
      "(2000, 139)\n",
      "(2000, 139)\n"
     ]
    }
   ],
   "source": [
    "Idle_data = pd.read_csv('..\\HandTrackingData\\IdleData.csv')\n",
    "Idle_data = Idle_data.to_numpy()\n",
    "\n",
    "Pistol_data = pd.read_csv('..\\HandTrackingData\\PistalData.csv')\n",
    "Pistol_data = Pistol_data.to_numpy()\n",
    "\n",
    "Drill_data = pd.read_csv('..\\HandTrackingData\\DrillData.csv')\n",
    "Drill_data = Drill_data.to_numpy()\n",
    "\n",
    "Sword_data = pd.read_csv('..\\HandTrackingData\\SwordData.csv')\n",
    "Sword_data = Sword_data.to_numpy()\n",
    "\n",
    "Dagger_data = pd.read_csv('..\\HandTrackingData\\DaggerData.csv')\n",
    "Dagger_data = Dagger_data.to_numpy()\n",
    "\n",
    "KitchenKnife_data = pd.read_csv('..\\HandTrackingData\\KitchenKnifeData.csv')\n",
    "KitchenKnife_data = KitchenKnife_data.to_numpy()\n",
    "\n",
    "print(Idle_data.shape)\n",
    "print(Pistol_data.shape)\n",
    "print(Drill_data.shape)\n",
    "print(Sword_data.shape)\n",
    "print(Dagger_data.shape)\n",
    "print(KitchenKnife_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Idle_data_Seq= []\n",
    "Pistol_data_Seq = []\n",
    "Drill_data_Seq = []\n",
    "Sword_data_Seq = []\n",
    "Dagger_data_Seq = []\n",
    "KitchenKnife_data_Seq = []\n",
    "\n",
    "\n",
    "Objects = ['Idle','Pistol', 'Drill', 'Sword', 'Dagger', 'KitchenKnife']\n",
    "WindowSize = 80\n",
    "#secs_for_action = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Create_Sequences(data, window_size):\n",
    "    \"\"\"\n",
    "    주어진 데이터와 윈도우 크기를 기반으로 시퀀스를 생성합니다.\n",
    "\n",
    "    Args:\n",
    "        data (list or np.ndarray): 입력 데이터\n",
    "        window_size (int): 시퀀스의 윈도우 크기\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: 생성된 시퀀스 배열\n",
    "    \"\"\"\n",
    "    \n",
    "    Sequences = []\n",
    "    for seq in range(len(data) - window_size):\n",
    "        Sequences.append(data[seq:seq + window_size])\n",
    "    return np.array(Sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Idle_data_Seq = Create_Sequences(Idle_data, WindowSize)\n",
    "Pistol_data_Seq = Create_Sequences(Pistol_data, WindowSize)\n",
    "Drill_data_Seq = Create_Sequences(Drill_data, WindowSize)\n",
    "Sword_data_Seq = Create_Sequences(Sword_data, WindowSize)\n",
    "Dagger_data_Seq = Create_Sequences(Dagger_data, WindowSize)\n",
    "KitchenKnife_data_Seq = Create_Sequences(KitchenKnife_data, WindowSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1920, 80, 139)\n",
      "(1920, 80, 139)\n",
      "(1920, 80, 139)\n",
      "(1920, 80, 139)\n",
      "(1920, 80, 139)\n",
      "(1920, 80, 139)\n"
     ]
    }
   ],
   "source": [
    "print(Idle_data_Seq.shape)\n",
    "print(Pistol_data_Seq.shape)\n",
    "print(Drill_data_Seq.shape)\n",
    "print(Sword_data_Seq.shape)\n",
    "print(Dagger_data_Seq.shape)\n",
    "print(KitchenKnife_data_Seq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11520, 80, 139)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ConcatenatedSeqData = np.concatenate([Idle_data_Seq, Pistol_data_Seq , Drill_data_Seq, Sword_data_Seq, Dagger_data_Seq, KitchenKnife_data_Seq], axis=0)\n",
    "\n",
    "ConcatenatedSeqData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 5. 5. 5.]\n"
     ]
    }
   ],
   "source": [
    "# 이거 임시로 -2로 둔거, 마지막 데이터 고치면 -1로 바꿔야함.\n",
    "X_data = ConcatenatedSeqData[:, :, :-1]\n",
    "Labels = ConcatenatedSeqData[:, 0, -1]\n",
    "\n",
    "#Labels = np.zeros_like(Labels)\n",
    "\n",
    "#print(X_data.shape)\n",
    "#print(X_data)\n",
    "\n",
    "#print(Labels.shape)\n",
    "print(Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "Y_data = to_categorical(Labels, num_classes=len(Objects))\n",
    "\n",
    "print(Y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9216, 80, 138) (9216, 6)\n",
      "(2304, 80, 138) (2304, 6)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_data = X_data.astype(np.float32)\n",
    "Y_data = Y_data.astype(np.float32)\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_data, Y_data, test_size=0.2, random_state=2024)\n",
    "\n",
    "print(X_train.shape, Y_train.shape)\n",
    "print(X_val.shape, Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 64)                51968     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 198       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 54,246\n",
      "Trainable params: 54,246\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "model = Sequential([\n",
    "    #LSTM(64, activation='tanh', input_shape=X_train.shape[1:3]),\n",
    "    LSTM(64, activation='tanh', input_shape=(80, 138)),\n",
    "    Dense(32, activation='tanh'),\n",
    "    Dense(len(Objects), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 형식: (None, 80, 138)\n"
     ]
    }
   ],
   "source": [
    "print(\"입력 형식:\", model.input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    validation_data=(X_val, Y_val),\n",
    "    epochs=100,\n",
    "    callbacks=[\n",
    "        ModelCheckpoint('models/model3.h5', monitor='val_acc', verbose=1, save_best_only=True, mode='auto'),\n",
    "        ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=50, verbose=1, mode='auto')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots(figsize=(16, 10))\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(history.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(history.history['val_loss'], 'r', label='val loss')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "loss_ax.legend(loc='upper left')\n",
    "\n",
    "acc_ax.plot(history.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(history.history['val_acc'], 'g', label='val acc')\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "acc_ax.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\model3_tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\model3_tf\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SavedModel saved at: models\\model3_tf\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# .h5 모델 로드\n",
    "h5_model_path = \"models\\model3.h5\"\n",
    "saved_model_path = \"models\\model3_tf\"\n",
    "\n",
    "model = tf.keras.models.load_model(h5_model_path)\n",
    "\n",
    "# SavedModel 형식으로 저장\n",
    "tf.saved_model.save(model, saved_model_path)\n",
    "\n",
    "print(f\"SavedModel saved at: {saved_model_path}\")\n",
    "\n",
    "#tf python -m tf2onnx.convert --saved-model C:\\Project\\saved_model --output C:\\Project\\model2.onnx\n",
    "#python -m tf2onnx.convert --saved-model tensorflow-model-path --output model.onnx\n",
    "#python -m tf2onnx.convert --input model3.h5 --output model33.onnx\n",
    "#python -m tf2onnx.convert --saved-model path/to/saved_model --output model.onnx --input-shape \"1,80,138\"\n",
    "\n",
    "# 사용해서 onnx 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "\n",
    "# onnx 파일 구조 파악.\n",
    "onnx_model = onnx.load(\"D:\\GripGenObject\\LSTMModel\\models\\model3.onnx\")\n",
    "onnx.checker.check_model(onnx_model)\n",
    "\n",
    "print(onnx.helper.printable_graph(onnx_model.graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "\n",
    "# onnx 파일 구조 파악.\n",
    "onnx_model = onnx.load(\"C:\\Project\\[KHU-GameEngineering]_LSTM_Hand_Pred\\KHU-GameEngineering-HandsPred\\model12.onnx\")\n",
    "onnx.checker.check_model(onnx_model)\n",
    "\n",
    "print(onnx.helper.printable_graph(onnx_model.graph))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
